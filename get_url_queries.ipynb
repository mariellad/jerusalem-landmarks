{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4339c89d",
   "metadata": {},
   "source": [
    "## Get urls for all jerusalem images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09f16610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from dbfread import DBF\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "import json\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f976678",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Adapted from the LOC github.\n",
    "This will allow us to store the web address for each item in a list, working through the search page by page.\n",
    "\n",
    "'''\n",
    "def get_image_urls(url, items=[]):\n",
    "    '''\n",
    "    Retrieves the image_ruls for items that have public URLs available. \n",
    "    Skips over items that are for the collection as a whole or web pages about the collection.\n",
    "    Handles pagination. \n",
    "    '''\n",
    "    # request pages of 100 results at a time\n",
    "    params = {\"fo\": \"json\", \"c\": 100, \"at\": \"results,pagination\"}\n",
    "    call = requests.get(url, params=params)\n",
    "    data = call.json()\n",
    "    results = data['results']\n",
    "    for result in results:\n",
    "        # don't try to get images from the collection-level result\n",
    "        if \"collection\" not in result.get(\"original_format\") and \"web page\" not in result.get(\"original_format\"):\n",
    "            # take the last URL listed in the image_url array\n",
    "            item = result.get(\"id\")\n",
    "            items.append(item)\n",
    "    if data[\"pagination\"][\"next\"] is not None: # make sure we haven't hit the end of the pages\n",
    "        next_url = data[\"pagination\"][\"next\"]\n",
    "        #print(\"getting next page: {0}\".format(next_url))\n",
    "        get_image_urls(next_url, items)\n",
    "        \n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d448b410",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the urls\n",
    "jerusalem = get_image_urls(\"https://www.loc.gov/photos/?fa=online-format:image&q=jerusalem\", items=[])\n",
    "#Checking the total number of results\n",
    "len(jerusalem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c7fa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the list\n",
    "df_jerusalem = pd.DataFrame(jerusalem, columns=['URLs'])\n",
    "# Save the DataFrame to a CSV file\n",
    "df_jerusalem.to_csv('./jerusalem_urls.csv', index=False)\n",
    "file_path = './jerusalem_urls.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5e2ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 300 random urls from the list for testing\n",
    "random_jerusalem = random.sample(jerusalem, 300)\n",
    "#Save them in a csv file\n",
    "df_random = pd.DataFrame(random_jerusalem, columns=['URLs'])\n",
    "df_jerusalem.to_csv('./random_jerusalem.csv', index=False)\n",
    "file_path = './random_jerusalem.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2587f576",
   "metadata": {},
   "source": [
    "## Get urls for images of each landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a17366d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to DBF file\n",
    "file_path = \"./landmarks_names/landmarks_names/landmarks_names.dbf\"\n",
    "\n",
    "encoding = 'utf-8' \n",
    "\n",
    "# Create an empty list to store records\n",
    "records = []\n",
    "\n",
    "# Read the DBF file and iterate through records with the specified encoding\n",
    "with DBF(file_path, encoding=encoding) as dbf:\n",
    "    for record in dbf:\n",
    "        records.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb48c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of records into a pandas DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# Stack all the columns of the dataframe into a single column\n",
    "# This ignores any NaN, None, or empty strings during the process\n",
    "stacked_series = df.stack().reset_index(drop=True)\n",
    "\n",
    "# Remove any empty strings or NaN values that might be present\n",
    "stacked_series.replace('', pd.NA, inplace=True)\n",
    "stacked_series.dropna(inplace=True)\n",
    "\n",
    "# Convert the series into a DataFrame\n",
    "df_single_column = pd.DataFrame(stacked_series, columns=['Names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc335b0",
   "metadata": {},
   "source": [
    "#### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce95f053",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to remove tabs\n",
    "def remove_quadruple_tabs_if_exists(s):\n",
    "    \"\"\"Remove occurrences of '\\t\\t\\t\\t' from the input string if it exists.\"\"\"\n",
    "    if '\\t\\t\\t\\t' in s:\n",
    "        return s.replace('\\t\\t\\t\\t', '')\n",
    "    if '\\t\\t\\t\\t\\t' in s:\n",
    "        return s.replace('\\t\\t\\t\\t\\t', '')   \n",
    "    else:\n",
    "        return s\n",
    "\n",
    "# Applying the function to each string in the list\n",
    "df_single_column['Names'] = [remove_quadruple_tabs_if_exists(s) for s in df_single_column['Names']]\n",
    "\n",
    "# Removing apostrophes from the 'Name' column\n",
    "df_single_column['Names'] = df_single_column['Names'].str.replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a266c447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace spaces with '+' in the 'Name' column\n",
    "df_single_column['formatted_names'] = df_single_column['Names'].str.replace(' ', '+', regex=False)\n",
    "\n",
    "# Create the base URL\n",
    "base_url = 'https://www.loc.gov/photos/?fa=location:jerusalem&q='\n",
    "\n",
    "# Concatenate the base URL with the formatted 'Name' column and assign it to the new 'url' column\n",
    "df_single_column['url'] = base_url + df_single_column['formatted_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77bd67c",
   "metadata": {},
   "source": [
    "#### Getting URLs of each landmark in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838684a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_single_column['image_urls'] =  df_single_column['url'].apply(get_image_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a91585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the number of results for each landmark \n",
    "df_single_column['count'] = df_single_column['image_urls'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfeedc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the total number of results\n",
    "total_count = df_single_column['count'].sum()\n",
    "\n",
    "print(\"Total number:\", total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ab229a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving results in a DataFrame\n",
    "df_total = df_single_column.explode('image_urls').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23734b9f",
   "metadata": {},
   "source": [
    "## Get unique urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73c355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the urls that were present in the 'jerusalem' search query, but not in any of the other landmark queries\n",
    "jerusalem_set = set(df_jerusalem['URLs'])\n",
    "total_set = set(df_total['image_urls'])\n",
    "unique_urls = jerusalem_set - total_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15158f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the number of unique urls\n",
    "len(unique_urls)\n",
    "\n",
    "#calculate the percentage of unique urls\n",
    "unique_per = (len(unique_urls)/len(jerusalem))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27ed7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame\n",
    "df_unique_urls = pd.DataFrame(unique_urls, columns=['URLs'])\n",
    "# Save the DataFrame to a CSV file\n",
    "df_unique_urls.to_csv('./unique_urls.csv', index=False)\n",
    "file_path = './unique_urls.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0813c749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 300 random urls from the list for testing\n",
    "random_unique_urls = random.sample(unique_urls, 300)\n",
    "df_random_unique_urls = pd.DataFrame(random_unique_urls, columns=['URLs'])\n",
    "df_random_unique_urls.to_csv('./random_unique_urls.csv', index=False)\n",
    "file_path = './random_unique_urls.csv'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
